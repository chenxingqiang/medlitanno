#!/usr/bin/env python3
"""
LLM-based Automated Annotation System for Medical Literature
è‡ªåŠ¨åŒ–åŒ»å­¦æ–‡çŒ®æ ‡æ³¨ç³»ç»Ÿ

This system replaces manual annotation in Label Studio with LLM-powered automation
for identifying bacteria-disease relationships in medical abstracts.
"""

import pandas as pd
import json
import os
import re
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from pathlib import Path
import requests
from openai import OpenAI


@dataclass
class Entity:
    """å®ä½“ç±»"""
    text: str
    label: str  # 'Bacteria' or 'Disease'
    start_pos: int
    end_pos: int


@dataclass
class Evidence:
    """è¯æ®ç±»"""
    text: str
    start_pos: int
    end_pos: int
    relation_type: str  # 'contributes_to', 'ameliorates', 'correlated_with', 'biomarker_for'


@dataclass
class Relation:
    """å…³ç³»ç±»"""
    subject: Entity  # Bacteria
    object: Entity   # Disease
    evidence: Evidence
    relation_type: str


@dataclass
class AnnotationResult:
    """æ ‡æ³¨ç»“æœ"""
    pmid: str
    title: str
    abstract: str
    entities: List[Entity]
    evidences: List[Evidence]
    relations: List[Relation]


class MedicalAnnotationLLM:
    """åŒ»å­¦æ–‡çŒ®è‡ªåŠ¨æ ‡æ³¨ç³»ç»Ÿ"""

    def __init__(self, api_key: str, model: str = "gpt-4o", model_type: str = "openai", base_url: str = None):
        """
        åˆå§‹åŒ–LLMæ ‡æ³¨ç³»ç»Ÿ

        Args:
            api_key: APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            model_type: æ¨¡å‹ç±»å‹ ('openai', 'deepseek', 'qianwen')
            base_url: APIåŸºç¡€URLï¼ˆå¯é€‰ï¼‰
        """
        self.api_key = api_key
        self.model = model
        self.model_type = model_type.lower()

        # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®å®¢æˆ·ç«¯å’Œé…ç½®
        if self.model_type == "openai":
            self.client = OpenAI(api_key=api_key, base_url=base_url) if base_url else OpenAI(api_key=api_key)
        elif self.model_type == "deepseek":
            self.client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com/v1"
            )
            if model == "gpt-4o":  # å¦‚æœæ²¡æœ‰æŒ‡å®šDeepSeekæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤çš„
                self.model = "deepseek-chat"
        elif self.model_type == "deepseek-reasoner":
            self.client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com/v1"
            )
            # ä½¿ç”¨æ¨ç†æ¨¡å‹ï¼Œç‰¹åˆ«é€‚åˆä»æ‘˜è¦ä¸­è¿›è¡Œå¤æ‚æ¨ç†
            if model in ["gpt-4o", "deepseek-chat"]:
                self.model = "deepseek-reasoner"
        elif self.model_type == "qianwen":
            self.client = OpenAI(
                api_key=api_key,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )
            if model == "gpt-4o":  # å¦‚æœæ²¡æœ‰æŒ‡å®šQianwenæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤çš„
                self.model = "qwen-plus"
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}. æ”¯æŒçš„ç±»å‹: openai, deepseek, deepseek-reasoner, qianwen")

        # æ ‡æ³¨æç¤ºè¯æ¨¡æ¿ - é’ˆå¯¹ä¸åŒæ¨¡å‹ä¼˜åŒ–
        if self.model_type == "deepseek-reasoner":
            # ä¸ºæ¨ç†æ¨¡å‹ä¼˜åŒ–çš„æç¤ºè¯ï¼Œå¼ºè°ƒé€»è¾‘æ¨ç†å’Œæ·±åº¦åˆ†æ
            self.annotation_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦æ–‡çŒ®æ ‡æ³¨ä¸“å®¶ï¼Œå…·æœ‰å¼ºå¤§çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚è¯·æ·±åº¦åˆ†æä»¥ä¸‹åŒ»å­¦æ‘˜è¦ï¼Œè¿ç”¨ä½ çš„æ¨ç†èƒ½åŠ›ä»æœ‰é™çš„ä¿¡æ¯ä¸­æ¨æ–­å‡ºéšå«çš„å…³ç³»ã€‚

**åˆ†æä»»åŠ¡ï¼š**
ä»åŒ»å­¦æ‘˜è¦ä¸­æ¨ç†å¹¶æ ‡æ³¨ç—…åŸå¾®ç”Ÿç‰©ä¸è‡ªèº«å…ç–«æ€§ç–¾ç—…çš„å…³ç³»ã€‚

**æ¨ç†æ­¥éª¤ï¼š**

**ç¬¬ä¸€æ­¥ï¼šæ·±åº¦å®ä½“è¯†åˆ«ä¸æ¨ç†**
1. Bacteriaï¼ˆç—…åŸå¾®ç”Ÿç‰©ï¼‰ï¼šä¸ä»…è¯†åˆ«æ˜ç¡®æåˆ°çš„ï¼Œè¿˜è¦æ¨ç†å¯èƒ½ç›¸å…³çš„ç—…åŸä½“
   - ç»†èŒã€ç—…æ¯’ã€å¯„ç”Ÿè™«ã€çœŸèŒç­‰
   - æ³¨æ„éšå«æåŠçš„ç—…åŸä½“ï¼ˆå¦‚"æ„ŸæŸ“"ã€"ç—…åŸä½“"ç­‰ï¼‰
2. Diseaseï¼ˆè‡ªèº«å…ç–«æ€§ç–¾ç—…ï¼‰ï¼šè¯†åˆ«æ‰€æœ‰ç›¸å…³çš„è‡ªèº«å…ç–«æ€§ç–¾ç—…
   - åŒ…æ‹¬ç–¾ç—…çš„ä¸åŒè¡¨ç°å½¢å¼å’Œé˜¶æ®µ

**ç¬¬äºŒæ­¥ï¼šè¯æ®æ·±åº¦æŒ–æ˜ä¸å…³ç³»æ¨ç†**
åŸºäºæ‘˜è¦å†…å®¹ï¼Œæ·±åº¦æ¨ç†ç—…åŸå¾®ç”Ÿç‰©ä¸ç–¾ç—…çš„å…³ç³»ç±»å‹ï¼š
- contributes_toï¼ˆè‡´ç—…ä½œç”¨ï¼‰ï¼šé€šè¿‡åˆ†å­æ¨¡æ‹Ÿã€å…ç–«æ¿€æ´»ã€äº¤å‰ååº”ç­‰æœºåˆ¶å¯¼è‡´ç–¾ç—…
- amelioratesï¼ˆä¿æŠ¤ä½œç”¨ï¼‰ï¼šé€šè¿‡å…ç–«è°ƒèŠ‚ã€ç«äº‰æŠ‘åˆ¶ç­‰æœºåˆ¶ä¿æŠ¤å®¿ä¸»
- correlated_withï¼ˆæµè¡Œç—…å­¦å…³è”ï¼‰ï¼šç»Ÿè®¡å­¦ç›¸å…³ä½†æœºåˆ¶ä¸æ˜ç¡®
- biomarker_forï¼ˆè¯Šæ–­ä»·å€¼ï¼‰ï¼šå¯ç”¨äºç–¾ç—…è¯Šæ–­ã€é¢„åæˆ–åˆ†å±‚

**ç¬¬ä¸‰æ­¥ï¼šé€»è¾‘å…³ç³»æ„å»º**
è¿ç”¨åŒ»å­¦çŸ¥è¯†å’Œé€»è¾‘æ¨ç†ï¼Œå°†å®ä½“ä¸è¯æ®ç²¾ç¡®å…³è”ã€‚

**æ¨ç†è¦ç‚¹ï¼š**
- è€ƒè™‘åˆ†å­æœºåˆ¶ï¼ˆå¦‚åˆ†å­æ¨¡æ‹Ÿã€äº¤å‰ååº”ï¼‰
- åˆ†æå…ç–«å­¦è¿‡ç¨‹ï¼ˆå¦‚Th1/Th2å¹³è¡¡ã€è°ƒèŠ‚æ€§Tç»†èƒï¼‰
- è¯„ä¼°æ—¶é—´å…³ç³»ï¼ˆæ„ŸæŸ“å…ˆäºç–¾ç—…å‘ç”Ÿï¼‰
- è€ƒè™‘å‰‚é‡æ•ˆåº”å…³ç³»

**å¾…åˆ†ææ–‡æœ¬ï¼š**
Title: {title}
Abstract: {abstract}

{{
    "entities": [
        {{
            "text": "å®ä½“æ–‡æœ¬",
            "label": "Bacteria/Disease",
            "start_pos": èµ·å§‹ä½ç½®,
            "end_pos": ç»“æŸä½ç½®
        }}
    ],
    "evidences": [
        {{
            "text": "è¯æ®å¥å­",
            "start_pos": èµ·å§‹ä½ç½®,
            "end_pos": ç»“æŸä½ç½®,
            "relation_type": "contributes_to/ameliorates/correlated_with/biomarker_for"
        }}
    ],
    "relations": [
        {{
            "subject_text": "ç—…åŸä½“å®ä½“æ–‡æœ¬",
            "object_text": "ç–¾ç—…å®ä½“æ–‡æœ¬",
            "evidence_text": "è¯æ®å¥å­",
            "relation_type": "å…³ç³»ç±»å‹"
        }}
    ]
}}

è¯·è¿ç”¨ä½ çš„æ¨ç†èƒ½åŠ›æ·±åº¦åˆ†æï¼Œç¡®ä¿è¾“å‡ºçš„JSONæ ¼å¼æ­£ç¡®ã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³å®ä½“æˆ–å…³ç³»ï¼Œè¯·è¿”å›ç©ºæ•°ç»„ã€‚
"""
        else:
            # ä¸ºå…¶ä»–æ¨¡å‹ä½¿ç”¨æ ‡å‡†æç¤ºè¯
            self.annotation_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦æ–‡çŒ®æ ‡æ³¨ä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æä»¥ä¸‹åŒ»å­¦æ‘˜è¦ï¼ŒæŒ‰ç…§ä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤è¿›è¡Œæ ‡æ³¨ï¼š

**ç¬¬ä¸€æ­¥ï¼šå®ä½“è¯†åˆ«**
è¯†åˆ«æ–‡æœ¬ä¸­çš„ä¸¤ç±»å®ä½“ï¼š
1. Bacteriaï¼ˆè‡´ç—…èŒï¼‰ï¼šåŒ…æ‹¬ç»†èŒã€ç—…æ¯’ã€å¯„ç”Ÿè™«ã€çœŸèŒç­‰ç—…åŸå¾®ç”Ÿç‰©
2. Diseaseï¼ˆè‡ªèº«å…ç–«æ€§ç–¾ç—…ï¼‰ï¼šåŒ…æ‹¬å„ç§è‡ªèº«å…ç–«æ€§ç–¾ç—…

**ç¬¬äºŒæ­¥ï¼šè¯æ®è¯†åˆ«**
æ‰¾åˆ°æè¿°ç—…åŸå¾®ç”Ÿç‰©ä¸ç–¾ç—…å…³ç³»çš„å®Œæ•´å¥å­ï¼Œå¹¶åˆ¤æ–­å…³ç³»ç±»å‹ï¼š
- contributes_toï¼ˆè´Ÿé¢å½±å“ï¼‰ï¼šç—…åŸä½“å¯¼è‡´ã€è§¦å‘ã€åŠ å‰§ã€ä¿ƒè¿›äº†ç–¾ç—…
- amelioratesï¼ˆæ­£é¢å½±å“ï¼‰ï¼šç—…åŸä½“æ”¹å–„ã€ç¼“è§£ã€æŠ‘åˆ¶ã€æ²»ç–—äº†ç–¾ç—…
- correlated_withï¼ˆç»Ÿè®¡å…³è”ï¼‰ï¼šåªæè¿°äº†ç—…åŸä½“ä¸ç–¾ç—…çš„ç›¸å…³æ€§ï¼Œæœªæ˜ç¡®å› æœå…³ç³»
- biomarker_forï¼ˆåº”ç”¨åŠŸèƒ½ï¼‰ï¼šç—…åŸä½“å¯ä½œä¸ºç–¾ç—…è¯Šæ–­ã€é¢„æµ‹æˆ–åˆ†å‹çš„ç”Ÿç‰©æ ‡å¿—ç‰©

**ç¬¬ä¸‰æ­¥ï¼šå…³ç³»æ„å»º**
å°†è¯†åˆ«çš„å®ä½“å’Œè¯æ®å…³è”èµ·æ¥ã€‚

**å¾…æ ‡æ³¨æ–‡æœ¬ï¼š**
Title: {title}
Abstract: {abstract}

**è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼ï¼‰ï¼š**
{{
    "entities": [
        {{
            "text": "å®ä½“æ–‡æœ¬",
            "label": "Bacteria/Disease",
            "start_pos": èµ·å§‹ä½ç½®,
            "end_pos": ç»“æŸä½ç½®
        }}
    ],
    "evidences": [
        {{
            "text": "è¯æ®å¥å­",
            "start_pos": èµ·å§‹ä½ç½®,
            "end_pos": ç»“æŸä½ç½®,
            "relation_type": "contributes_to/ameliorates/correlated_with/biomarker_for"
        }}
    ],
    "relations": [
        {{
            "subject_text": "ç—…åŸä½“å®ä½“æ–‡æœ¬",
            "object_text": "ç–¾ç—…å®ä½“æ–‡æœ¬",
            "evidence_text": "è¯æ®å¥å­",
            "relation_type": "å…³ç³»ç±»å‹"
        }}
    ]
}}

è¯·ç¡®ä¿è¾“å‡ºçš„JSONæ ¼å¼æ­£ç¡®ï¼Œä½ç½®ä¿¡æ¯å‡†ç¡®ã€‚å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³å®ä½“æˆ–å…³ç³»ï¼Œè¯·è¿”å›ç©ºæ•°ç»„ã€‚
"""

    def _call_llm(self, messages: List[Dict]) -> str:
        """
        è°ƒç”¨LLM API

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨

        Returns:
            str: LLMå“åº”å†…å®¹
        """
        try:
            if self.model_type in ["openai", "deepseek", "deepseek-reasoner", "qianwen"]:
                # ä¸ºdeepseek-reasonerè°ƒæ•´å‚æ•°ä»¥è·å¾—æ›´å¥½çš„æ¨ç†æ•ˆæœ
                if self.model_type == "deepseek-reasoner":
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=messages,
                        temperature=0.2,  # ç¨é«˜çš„æ¸©åº¦ä»¥ä¿ƒè¿›åˆ›é€ æ€§æ¨ç†
                        max_tokens=3000,  # æ›´å¤štokenä»¥æ”¯æŒå¤æ‚æ¨ç†
                        top_p=0.9
                    )
                else:
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=messages,
                        temperature=0.1,  # é™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
                        max_tokens=2000
                    )
                return response.choices[0].message.content.strip()
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")

        except Exception as e:
            raise Exception(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")

    def annotate_text(self, title: str, abstract: str, pmid: str = "") -> AnnotationResult:
        """
        å¯¹å•ç¯‡æ–‡çŒ®è¿›è¡Œè‡ªåŠ¨æ ‡æ³¨

        Args:
            title: æ–‡ç« æ ‡é¢˜
            abstract: æ–‡ç« æ‘˜è¦
            pmid: PubMed ID

        Returns:
            AnnotationResult: æ ‡æ³¨ç»“æœ
        """
        # åˆå¹¶æ ‡é¢˜å’Œæ‘˜è¦ä½œä¸ºå®Œæ•´æ–‡æœ¬
        full_text = f"{title}\n{abstract}"

        # æ„å»ºæç¤ºè¯
        prompt = self.annotation_prompt.format(title=title, abstract=abstract)

        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦æ–‡çŒ®æ ‡æ³¨ä¸“å®¶ï¼Œä¸“é—¨è¯†åˆ«ç—…åŸå¾®ç”Ÿç‰©ä¸è‡ªèº«å…ç–«æ€§ç–¾ç—…ä¹‹é—´çš„å…³ç³»ã€‚"},
            {"role": "user", "content": prompt}
        ]

        try:
            # è°ƒç”¨LLMè¿›è¡Œæ ‡æ³¨
            llm_output = self._call_llm(messages)

            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', llm_output, re.DOTALL)
            if not json_match:
                print(f"Warning: No JSON found in LLM response for PMID {pmid}")
                return self._create_empty_result(pmid, title, abstract)

            try:
                annotation_data = json.loads(json_match.group())
            except json.JSONDecodeError as e:
                print(f"Warning: JSON parsing error for PMID {pmid}: {e}")
                return self._create_empty_result(pmid, title, abstract)

            # è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®
            return self._parse_annotation_data(annotation_data, pmid, title, abstract, full_text)

        except Exception as e:
            print(f"Error annotating PMID {pmid}: {e}")
            return self._create_empty_result(pmid, title, abstract)

    def _create_empty_result(self, pmid: str, title: str, abstract: str) -> AnnotationResult:
        """åˆ›å»ºç©ºçš„æ ‡æ³¨ç»“æœ"""
        return AnnotationResult(
            pmid=pmid,
            title=title,
            abstract=abstract,
            entities=[],
            evidences=[],
            relations=[]
        )

    def _parse_annotation_data(self, data: Dict, pmid: str, title: str, abstract: str, full_text: str) -> AnnotationResult:
        """è§£æLLMè¿”å›çš„æ ‡æ³¨æ•°æ®"""
        entities = []
        evidences = []
        relations = []

        # è§£æå®ä½“
        for entity_data in data.get('entities', []):
            entity = Entity(
                text=entity_data['text'],
                label=entity_data['label'],
                start_pos=entity_data.get('start_pos', 0),
                end_pos=entity_data.get('end_pos', 0)
            )
            entities.append(entity)

        # è§£æè¯æ®
        for evidence_data in data.get('evidences', []):
            evidence = Evidence(
                text=evidence_data['text'],
                start_pos=evidence_data.get('start_pos', 0),
                end_pos=evidence_data.get('end_pos', 0),
                relation_type=evidence_data['relation_type']
            )
            evidences.append(evidence)

        # è§£æå…³ç³»
        for relation_data in data.get('relations', []):
            # æŸ¥æ‰¾å¯¹åº”çš„å®ä½“
            subject_entity = None
            object_entity = None
            evidence_obj = None

            for entity in entities:
                if entity.text == relation_data['subject_text'] and entity.label == 'Bacteria':
                    subject_entity = entity
                elif entity.text == relation_data['object_text'] and entity.label == 'Disease':
                    object_entity = entity

            for evidence in evidences:
                if evidence.text == relation_data['evidence_text']:
                    evidence_obj = evidence
                    break

            if subject_entity and object_entity and evidence_obj:
                relation = Relation(
                    subject=subject_entity,
                    object=object_entity,
                    evidence=evidence_obj,
                    relation_type=relation_data['relation_type']
                )
                relations.append(relation)

        return AnnotationResult(
            pmid=pmid,
            title=title,
            abstract=abstract,
            entities=entities,
            evidences=evidences,
            relations=relations
        )

    def annotate_excel_file(self, excel_path: str, output_path: str = None) -> List[AnnotationResult]:
        """
        å¯¹Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰æ–‡çŒ®è¿›è¡Œæ‰¹é‡æ ‡æ³¨

        Args:
            excel_path: Excelæ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰

        Returns:
            List[AnnotationResult]: æ‰€æœ‰æ–‡çŒ®çš„æ ‡æ³¨ç»“æœ
        """
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(excel_path)
        results = []

        print(f"Processing {len(df)} articles from {excel_path} using {self.model_type.upper()} {self.model}")

        for idx, row in df.iterrows():
            pmid = str(row.get('pmid', ''))
            title = str(row.get('title', ''))
            abstract = str(row.get('abstract', ''))

            print(f"Processing {idx+1}/{len(df)}: PMID {pmid}")

            # è¿›è¡Œæ ‡æ³¨
            result = self.annotate_text(title, abstract, pmid)
            results.append(result)

        # ä¿å­˜ç»“æœ
        if output_path:
            self.save_results(results, output_path)

        return results

    def save_results(self, results: List[AnnotationResult], output_path: str):
        """ä¿å­˜æ ‡æ³¨ç»“æœåˆ°JSONæ–‡ä»¶"""
        output_data = []

        for result in results:
            result_dict = {
                'pmid': result.pmid,
                'title': result.title,
                'abstract': result.abstract,
                'model_info': {
                    'model_type': self.model_type,
                    'model_name': self.model
                },
                'entities': [
                    {
                        'text': entity.text,
                        'label': entity.label,
                        'start_pos': entity.start_pos,
                        'end_pos': entity.end_pos
                    }
                    for entity in result.entities
                ],
                'evidences': [
                    {
                        'text': evidence.text,
                        'start_pos': evidence.start_pos,
                        'end_pos': evidence.end_pos,
                        'relation_type': evidence.relation_type
                    }
                    for evidence in result.evidences
                ],
                'relations': [
                    {
                        'subject_text': relation.subject.text,
                        'subject_label': relation.subject.label,
                        'object_text': relation.object.text,
                        'object_label': relation.object.label,
                        'evidence_text': relation.evidence.text,
                        'relation_type': relation.relation_type
                    }
                    for relation in result.relations
                ]
            }
            output_data.append(result_dict)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        print(f"Results saved to {output_path}")

    def generate_statistics(self, results: List[AnnotationResult]) -> Dict:
        """ç”Ÿæˆæ ‡æ³¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'model_info': {
                'model_type': self.model_type,
                'model_name': self.model
            },
            'total_articles': len(results),
            'articles_with_entities': 0,
            'articles_with_relations': 0,
            'total_bacteria': 0,
            'total_diseases': 0,
            'total_relations': 0,
            'relation_types': {
                'contributes_to': 0,
                'ameliorates': 0,
                'correlated_with': 0,
                'biomarker_for': 0
            }
        }

        for result in results:
            if result.entities:
                stats['articles_with_entities'] += 1
            if result.relations:
                stats['articles_with_relations'] += 1

            for entity in result.entities:
                if entity.label == 'Bacteria':
                    stats['total_bacteria'] += 1
                elif entity.label == 'Disease':
                    stats['total_diseases'] += 1

            stats['total_relations'] += len(result.relations)

            for relation in result.relations:
                if relation.relation_type in stats['relation_types']:
                    stats['relation_types'][relation.relation_type] += 1

        return stats


def batch_process_directory(data_dir: str, output_dir: str = None, api_key: str = None, model: str = "deepseek-chat", model_type: str = "deepseek"):
    """
    æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶

    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„ (å·²å¼ƒç”¨ï¼Œç°åœ¨ä¿å­˜åœ¨å„è‡ªç›®å½•çš„annotationå­ç›®å½•ä¸‹)
        api_key: APIå¯†é’¥
        model: æ¨¡å‹åç§°
        model_type: æ¨¡å‹ç±»å‹
    """
    if api_key is None:
        raise ValueError("API key is required")

    # åˆå§‹åŒ–æ ‡æ³¨å™¨
    annotator = MedicalAnnotationLLM(api_key=api_key, model=model, model_type=model_type)

    # éå†æ‰€æœ‰Excelæ–‡ä»¶
    excel_files = []
    for root, dirs, files in os.walk(data_dir):
        for file in files:
            if file.endswith('.xlsx'):
                excel_files.append(os.path.join(root, file))

    print(f"ğŸ“Š å‘ç° {len(excel_files)} ä¸ªExcelæ–‡ä»¶å¾…å¤„ç†")
    print(f"Found {len(excel_files)} Excel files to process")
    print()

    for file_path in excel_files:
        try:
            print(f"=== Processing {file_path} ===")

            # åˆ›å»ºå¯¹åº”çš„annotationç›®å½•
            # ä¾‹å¦‚: datatrain/bacteria-ids-4937/A/Achalasia.xlsx
            # å˜æˆ: datatrain/bacteria-ids-4937/A/annotation/
            dir_path = os.path.dirname(file_path)
            annotation_dir = os.path.join(dir_path, "annotation")
            os.makedirs(annotation_dir, exist_ok=True)

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            base_name = os.path.splitext(os.path.basename(file_path))[0]
            output_file = os.path.join(annotation_dir, f"{base_name}_annotated_{model_type}.json")
            stats_file = os.path.join(annotation_dir, f"{base_name}_stats_{model_type}.json")

            # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
            if os.path.exists(output_file):
                print(f"â­ï¸  æ–‡ä»¶å·²å¤„ç†ï¼Œè·³è¿‡: {output_file}")
                continue

            # å¤„ç†æ–‡ä»¶
            results = annotator.annotate_excel_file(file_path)

            if results:
                # ä¿å­˜ç»“æœ
                annotator.save_results(results, output_file)

                # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
                stats = annotator.generate_statistics(results)
                with open(stats_file, 'w', encoding='utf-8') as f:
                    json.dump(stats, f, ensure_ascii=False, indent=2)

                print(f"Results saved to {output_file}")
                print(f"Statistics: {stats}")
                print()
            else:
                print(f"âš ï¸  å¤„ç†å¤±è´¥: {file_path}")
                print()

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å‡ºé”™ {file_path}: {e}")
            print()
            continue

    print("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
    print("Batch processing completed!")


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    DEEPSEEK_API_KEY = "sk-d02fca54e07f4bdfb1778aeb62ae7671"
    QIANWEN_API_KEY = "sk-296434b603504719b9f5aca8286f5166"

    DATA_DIR = "datatrain"
    OUTPUT_DIR = "annotated_results"

    # ä½¿ç”¨DeepSeekæ‰¹é‡å¤„ç†
    print("=== ä½¿ç”¨ DeepSeek æ¨¡å‹ ===")
    batch_process_directory(DATA_DIR, api_key=DEEPSEEK_API_KEY, model="deepseek-chat", model_type="deepseek")

    # ä½¿ç”¨Qianwenæ‰¹é‡å¤„ç†
    print("\n=== ä½¿ç”¨ Qianwen æ¨¡å‹ ===")
    batch_process_directory(DATA_DIR, api_key=QIANWEN_API_KEY, model="qwen-plus", model_type="qianwen")